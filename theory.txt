---

## ğŸ”¹ Member-1 â†’ *Data Profiling & Preprocessing*

*Kaam:* Dataset ka summary nikalna.
*Steps:*

1. Dataset read karna (pandas.read_csv("file.csv")).
2. Rows/Columns count karna â†’ df.shape.
3. Data types check karna â†’ df.dtypes.
4. Missing values check â†’ df.isnull().sum().
5. Class imbalance check (agar target column hai) â†’ df['target'].value_counts().
6. Simple preprocessing suggestions likhna (jaise â€œFill missing valuesâ€, â€œLabel encode categorical dataâ€).

ğŸ‘‰ Output: Ek dictionary ya JSON jisme dataset ka summary hoga.

---

## ğŸ”¹ Member-2 â†’ *Algorithm Recommendation Logic*

*Kaam:* Dataset ke features dekh kar best algorithm suggest karna.
*Steps:*

1. Profiling se output lena.
2. Rules define karna:

   * Agar dataset rows < 10k â†’ Logistic Regression / Decision Tree.
   * Agar dataset rows â‰¥ 10k â†’ Random Forest / XGBoost.
   * Agar target categorical hai â†’ Classification algorithms.
   * Agar target numeric hai â†’ Regression algorithms.
   * Agar imbalance hai â†’ Sampling technique + suitable algorithm.
3. Justification generate karna (short text).

ğŸ‘‰ Output: Ek string (Recommended Algorithm = â€œRandom Forestâ€, Reason = â€œDataset large & mixed featuresâ€).

---

## ğŸ”¹ Member-3 â†’ *Report Generation*

*Kaam:* User ko ek readable report dena.
*Steps:*

1. Dataset summary + recommended algorithm ko input lena.
2. Report create karna:

   * python-docx â†’ Word file.
   * reportlab â†’ PDF.
   * Simple graphs (matplotlib/seaborn) â†’ e.g. class distribution pie chart.
3. Report me sections:

   * Dataset Overview (rows, columns, missing values).
   * Algorithm Recommendation (name + short justification).
   * Optional: Graphs (class balance, data types count).

ğŸ‘‰ Output: report.pdf ya report.docx file.

---

## ğŸ”¹ Member-4 â†’ *Integration & Testing*

*Kaam:* Sab modules ko ek end-to-end flow me connect karna.
*Steps:*

1. Member 1, 2, 3 ke code import karke ek main script banana (main.py).
2. Flow:

   * User dataset upload kare.
   * Profiling run ho.
   * Recommendation module run ho.
   * Report generate ho.
3. Testing with multiple datasets (small, large, balanced, imbalanced).
4. Simple interface banana (optional):

   * CLI: python main.py --file dataset.csv.
   * Or Streamlit app: Upload dataset â†’ Click button â†’ Get recommendation + download report.

ğŸ‘‰ Output: Ek working pipeline jo start se end tak chale.